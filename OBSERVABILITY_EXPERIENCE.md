# 🎯 オブザーバビリティ体験ガイド

負荷テストを使って、オブザーバビリティの三本柱（メトリクス、トレース、ログ）を実際に体験するステップバイステップガイドです。

## 📋 前提条件

このガイドを始める前に、以下が起動していることを確認してください：

```bash
# インフラの確認
podman ps | grep -E "grafana|prometheus|tempo|loki|kafka"

# Camelアプリの確認
ps aux | grep spring-boot:run | grep -v grep
```

すべて起動していない場合：
```bash
cd /Users/kjin/mobills/observability/demo
./start-demo.sh

# 別ターミナルで
cd camel-app
mvn spring-boot:run
```

## 🎓 体験の流れ

1. **準備** - ツールを開いて準備する（5分）
2. **体験1** - メトリクスで異常を検知する（10分）
3. **体験2** - トレースでボトルネックを特定する（10分）
4. **体験3** - ログで根本原因を解明する（10分）
5. **体験4** - 三本柱を連携させる（15分）

**所要時間:** 約50分

---

## 準備：ツールを開く

### ステップ1: ブラウザでツールを開く

以下のURLを**別々のタブ**で開いてください：

1. **Grafana** - メイン監視ダッシュボード
   ```
   http://localhost:3000
   ```
   - ログイン: `admin` / `admin`
   - パスワード変更をスキップ

2. **Prometheus** - メトリクス詳細
   ```
   http://localhost:9090
   ```

3. **ターミナル** - 2つ用意
   - ターミナル1: 負荷テスト用
   - ターミナル2: ログ監視用

### ステップ2: Grafanaの準備

1. 左メニュー → 「Explore」をクリック
2. データソースが「Prometheus」になっていることを確認
3. このタブを **「メトリクスタブ」** として残しておく

### ステップ3: ターミナルの準備

**ターミナル2（ログ監視用）:**
```bash
cd /Users/kjin/mobills/observability/demo/camel-app
tail -f app.log | grep -E "オーダー|ERROR|支払い|配送"
```

これでログがリアルタイムで表示されます。

### ステップ4: 動作確認

**ターミナル1:**
```bash
cd /Users/kjin/mobills/observability/demo

# 軽いテストリクエスト
curl -X POST http://localhost:8080/camel/api/orders
```

ターミナル2でログが流れることを確認してください。

---

## 体験1：メトリクスで異常を検知する

### 🎯 学習目標
- メトリクスでシステム全体の傾向を把握
- 異常なパターンを検知
- 「いつから」「何が」異常かを特定

### ステップ1: ベースライン測定

まず、通常時のメトリクスを確認します。

**Grafana（メトリクスタブ）で以下のクエリを実行:**

1. 画面中央の大きな入力エリアをクリック
2. 以下のクエリをコピー&ペースト:
   ```promql
   rate(http_server_requests_seconds_count{application="camel-observability-demo"}[1m])
   ```
3. 右上の青い「Run query」ボタンをクリック
4. グラフが表示されます

> 💡 **詳しい手順が必要な場合:** [GRAFANA_HOWTO.md](GRAFANA_HOWTO.md) を参照

**📝 観察ポイント:**
- グラフは平坦またはごく低い値のはず
- これが「正常時」のベースライン

### ステップ2: 軽い負荷をかける

**ターミナル1:**
```bash
./load-test-simple.sh -c 20 -i 1
```

**Grafana:**
- グラフを見ながら待機
- リアルタイムでリクエスト数が増えるのを観察
- グラフが上昇 → これがリクエストレートの変化

**📝 確認できたこと:**
- ✅ メトリクスがリアルタイムで変化
- ✅ リクエストレートの上昇
- ✅ テスト終了後、徐々に下降

### ステップ3: メモリ使用量を確認

**Grafanaで新しいクエリを追加:**

```promql
jvm_memory_used_bytes{application="camel-observability-demo",area="heap"}
```

**📝 観察ポイント:**
- ヒープメモリの使用量
- 処理が増えるとメモリも増加
- GC（ガベージコレクション）で減少

### ステップ4: 異常パターンを作り出す

より高い負荷で異常な状態を作ります。

**ターミナル1:**
```bash
./load-test-concurrent.sh -r 200 -c 30 -d 45
```

**Grafana:**
1. 時間範囲を「Last 5 minutes」に設定（右上）
2. 以下のクエリを実行:

```promql
# リクエストレートの急上昇
rate(http_server_requests_seconds_count{application="camel-observability-demo"}[1m])
```

**📝 観察ポイント:**
- 📈 リクエストレートが急激に上昇
- 🔴 これが「異常検知」のシグナル
- ⏰ 「いつから」上昇したかが明確

### 🎓 学んだこと

- ✅ メトリクスは**トレンド**を示す
- ✅ ベースラインとの比較で**異常を検知**
- ✅ **「いつ」「何が」**変化したかがわかる
- ⚠️ でも、**「なぜ」「どこで」**はわからない → 次のステップへ

---

## 体験2：トレースでボトルネックを特定する

### 🎯 学習目標
- トレースでリクエストの処理フローを可視化
- ボトルネックの特定
- 「どこで」時間がかかっているか理解

### ステップ1: Tempoを開く

**Grafana:**
1. 左メニュー → 「Explore」
2. データソース切り替え → **「Tempo」**を選択
3. 画面上部の「Search」タブをクリック

### ステップ2: 負荷をかける

**ターミナル1:**
```bash
./load-test-concurrent.sh -r 100 -c 20 -d 30
```

**実行中に次のステップへ進みます**

### ステップ3: トレースを検索

**Tempo（GrafanaのExplore）:**
1. 「Search」タブで「Run query」をクリック
2. 最近のトレース一覧が表示される
3. どれか1つのトレースをクリック

**📝 表示される情報:**
- トレース全体のタイムライン
- 各スパン（処理ステップ）の名前
- 各スパンの処理時間

### ステップ4: ボトルネックを見つける

**トレースの詳細を確認:**

1. **トレース全体の構造を確認**
   ```
   order-consumer-route
     └─ validate-order-route
          └─ payment-processing-route  ← 注目！
               └─ shipping-route
   ```

2. **各スパンの時間を比較**
   - validate: 50-200ms
   - payment: **200-500ms** ← 最も長い！
   - shipping: 100-300ms

3. **視覚的に確認**
   - タイムラインで `payment-processing-route` のバーが最も長い
   - これがボトルネック！

### ステップ5: 複数のトレースを比較

**Tempo:**
1. 「戻る」ボタンで検索結果に戻る
2. 他のトレースもクリックして確認
3. 共通のパターンを探す

**📝 気づくこと:**
- すべてのトレースで `payment-processing-route` が遅い
- これは設計上の意図的な遅延
- 実際の開発では、ここを最適化する対象になる

### ステップ6: エラーのトレースを探す

**Tempo:**
1. 検索結果で処理時間ではなく「エラー」を探す
2. 赤色や警告マークがついているトレースをクリック
3. どのスパンでエラーが発生したか確認

**📝 観察ポイント:**
- エラーが発生したスパンが赤く表示される
- エラーの種類とメッセージが表示される
- 約10%の確率で `payment-processing-route` でエラー発生

### 🎓 学んだこと

- ✅ トレースは**処理フロー**を可視化
- ✅ **「どこで」**時間がかかっているか特定
- ✅ ボトルネックが一目でわかる
- ⚠️ でも、**「なぜ」エラーになったか**の詳細はまだ不明 → 次のステップへ

---

## 体験3：ログで根本原因を解明する

### 🎯 学習目標
- ログで詳細なエラー情報を確認
- トレースIDでログとトレースを紐付け
- 「なぜ」問題が起きたか理解

### ステップ1: エラーを発生させる

まず、エラーが含まれる負荷をかけます。

**ターミナル1:**
```bash
./load-test-concurrent.sh -r 100 -c 25 -d 30
```

**ターミナル2（ログ監視）:**
- ログが流れるのを観察
- 「ERROR」や「失敗」の文字を探す

### ステップ2: ログでエラーを確認

**ターミナル2のログから以下を探します:**

```
支払いエラー: <エラーメッセージ>
オーダー失敗: ORD-xxxxxxxx
```

**📝 観察ポイント:**
- エラーメッセージが表示される
- オーダーIDが記録されている
- どのルートでエラーが発生したかわかる

### ステップ3: Lokiでログを検索

**Grafana:**
1. 左メニュー → 「Explore」
2. データソース切り替え → **「Loki」**を選択
3. 以下のクエリを実行:

```logql
{app="camel-observability-demo"} |= "ERROR"
```

「Run query」をクリック

**📝 表示される情報:**
- エラーログが時系列で表示
- ログレベル（ERROR）
- タイムスタンプ
- エラーメッセージ

**💡 LogQLクエリのポイント:**
- `|=` は文字列検索（ログの生テキストから検索）
- JSON形式のログから特定のフィールドで検索する場合は `| json` が必要

### ステップ4: ログを詳しく見る

**Loki:**
1. いずれかのエラーログをクリック
2. 展開して詳細を確認

**📝 確認できる情報:**
- タイムスタンプ
- ログレベル
- メッセージ本文
- トレースID（もし含まれていれば）

### ステップ5: 特定のオーダーを追跡

エラーログから特定のオーダーIDをコピーして、そのオーダーに関するすべてのログを検索：

```logql
{app="camel-observability-demo"} |= "ORD-<オーダーID>"
```

**📝 確認できること:**
- そのオーダーの処理フロー全体
- どこで成功し、どこで失敗したか
- エラーに至るまでの経緯

**💡 検索のコツ:**
- オーダーIDなど、ログの生テキストに含まれる文字列は `|=` で検索
- JSONフィールド（`trace_id`, `level` など）で検索する場合は `| json | フィールド名="値"` を使用

### ステップ6: ログとトレースを相関させる

**理想的なワークフロー（トレースIDがある場合）:**

1. **Tempoでエラーのトレースを見つける**
   - Grafana → Explore → Tempo
   - トレース一覧から任意のトレースをクリック

2. **トレースIDをコピー**
   - 画面上部のトレースID（32文字の16進数）を**全文コピー**
   - 例: `c02efc99e65dce72bd88168c79edb8ad`

3. **Lokiで検索:**
   ```logql
   {app="camel-observability-demo"} | json | trace_id="<コピーした32文字のID>"
   ```
   
   **重要ポイント:**
   - ✅ **ダブルクォート (`"`)** を使用（バッククォート `` ` `` や `'` は不可）
   - ✅ **`| json`** パーサーが必須（これがないとtrace_idフィールドを認識できない）
   - ✅ **スペースなし**: `trace_id="..."` （`trace_id = "..."` は不可）
   - ✅ **32文字**: トレースIDは必ず32文字（不足していないか確認）

4. **そのトレースに関連するすべてのログを表示**

**📝 これの威力:**
- トレースで「どこ」を特定
- ログで「なぜ」を解明
- 完全な調査が可能！

> 💡 **詳しい構文ガイド:** [LOKI_QUERY_FIXES.md](LOKI_QUERY_FIXES.md) を参照

### 🎓 学んだこと

- ✅ ログは**詳細な情報**を提供
- ✅ **「なぜ」**エラーが発生したかわかる
- ✅ トレースIDで**ログとトレースを紐付け**
- ✅ 特定のリクエストを**追跡できる**

---

## 体験4：三本柱を連携させる

### 🎯 学習目標
- メトリクス → トレース → ログの流れを体験
- データ駆動型の障害対応を実践
- オブザーバビリティの真の価値を理解

### シナリオ：本番環境で異常を検知して原因を特定する

想定：「本番環境でエラーが増えている」という報告を受けた

### ステップ1: メトリクスで異常を検知（検知）

**まず、異常を作り出します:**

**ターミナル1:**
```bash
./load-test-stress.sh
```

**Grafana（Prometheus）:**
```promql
rate(http_server_requests_seconds_count{application="camel-observability-demo"}[1m])
```

**📊 メトリクスから読み取る:**
- ✅ リクエスト数が急増している
- ✅ いつから増加したか特定できる
- ❓ 「何が原因か？」を調査する必要がある

**メモを取る:**
```
異常検知時刻: <現在時刻>
症状: リクエストレートの急上昇
次のアクション: トレースで詳細調査
```

### ステップ2: トレースでボトルネックを特定（特定）

**Grafana（Tempo）:**
1. データソースをTempoに切り替え
2. 「Search」で最近のトレースを表示
3. **処理時間が最も長いトレースを探す**

**📊 トレースから読み取る:**
- ✅ `payment-processing-route` が200-500ms
- ✅ 他のルートは正常（50-200ms）
- ✅ ボトルネックを特定できた

**メモを更新:**
```
異常検知時刻: <時刻>
症状: リクエストレートの急上昇
ボトルネック: payment-processing-route（200-500ms）
次のアクション: ログで根本原因を調査
```

### ステップ3: ログで根本原因を解明（調査）

**トレースからトレースIDをコピー（もしあれば）**

**Grafana（Loki）:**

**方法1: 文字列でエラーログを検索**
```logql
{app="camel-observability-demo"} |= "payment-processing"
```

または特定のエラーログ：
```logql
{app="camel-observability-demo"} |= "支払い処理エラー"
```

**方法2: トレースIDで関連ログを全て表示**
```logql
{app="camel-observability-demo"} | json | trace_id="<Tempoからコピーした32文字のID>"
```

**方法3: ERRORレベルのログのみ表示**
```logql
{app="camel-observability-demo"} | json | level="ERROR"
```

**📊 ログから読み取る:**
- ✅ エラーメッセージ: "Payment processing failed"
- ✅ 発生頻度: 約10%
- ✅ 根本原因を特定
- ✅ トレースIDでトレースと紐付け可能

**最終レポート:**
```
============================================
障害調査レポート
============================================
検知時刻: <時刻>
症状: リクエストレート急上昇、一部失敗

調査結果:
1. メトリクス: 負荷増加を検知
2. トレース: payment-processing-routeがボトルネック
3. ログ: 支払い処理で間欠的にエラー発生

根本原因:
- payment-processing-routeの処理時間が長い（200-500ms）
- 約10%の確率で"Payment processing failed"エラー

推奨アクション:
- 支払い処理の最適化
- エラーハンドリングの改善
- タイムアウト設定の見直し
============================================
```

### ステップ4: 時系列で振り返る

**Prometheus:**
```promql
# エラー率の推移
rate(http_server_requests_seconds_count{application="camel-observability-demo",status=~"5.."}[1m])
```

**Grafana:**
- 時間範囲を「Last 15 minutes」に設定
- エラー率のグラフを確認

**📊 時系列分析:**
- ✅ 負荷が増えるとエラーも増加
- ✅ 特定の時間帯に集中
- ✅ パターンを理解できる

### 🎓 最終的に学んだこと

**オブザーバビリティの真の価値:**

1. **スピード**
   - 勘や経験に頼らない
   - データですぐに原因を特定
   - MTTR（平均修復時間）を大幅短縮

2. **精度**
   - 推測ではなく事実に基づく
   - 再現可能な調査プロセス
   - 誤った対応を防ぐ

3. **予防**
   - 異常の兆候を早期検知
   - 大きな障害になる前に対処
   - プロアクティブな運用

4. **継続的改善**
   - ボトルネックを数値化
   - 改善の効果を測定
   - データドリブンな意思決定

---

## 🎯 応用チャレンジ

### チャレンジ1: カスタムクエリを作成

**Prometheus:**
```promql
# 平均レスポンスタイム
rate(http_server_requests_seconds_sum{application="camel-observability-demo"}[1m]) / 
rate(http_server_requests_seconds_count{application="camel-observability-demo"}[1m])
```

### チャレンジ2: アラートルールを考える

どのような閾値でアラートを出すべきか考えてみましょう：

```promql
# レスポンスタイムが1秒を超えたらアラート？
avg_over_time(http_server_requests_seconds_sum[5m]) > 1

# エラー率が5%を超えたらアラート？
rate(http_server_requests_seconds_count{status=~"5.."}[5m]) / 
rate(http_server_requests_seconds_count[5m]) > 0.05
```

### チャレンジ3: 長時間監視

```bash
# 5分間継続的に負荷をかける
./load-test-concurrent.sh -r 1000 -c 30 -d 300
```

Grafanaで5分間の変化を観察：
- メモリリーク はあるか？
- パフォーマンス劣化 はあるか？
- GCの頻度 は適切か？

---

## 📚 まとめ

### オブザーバビリティの三本柱

| 柱 | 役割 | 質問に答える |
|----|------|-------------|
| **メトリクス** | 傾向と異常検知 | 「いつ」「何が」 |
| **トレース** | フローとボトルネック | 「どこで」 |
| **ログ** | 詳細と根本原因 | 「なぜ」 |

### モダンな障害対応フロー

```
1. 【検知】メトリクスで異常を発見
   ↓
2. 【特定】トレースで問題箇所を絞り込み
   ↓
3. 【調査】ログで根本原因を解明
   ↓
4. 【対応】データに基づいて修正
   ↓
5. 【検証】メトリクスで改善を確認
```

### 次のステップ

1. **実際のプロジェクトに適用**
   - まずメトリクスから始める
   - 徐々にトレースとログを追加

2. **アラートを設定**
   - 重要なメトリクスを監視
   - 異常時に通知

3. **ダッシュボードをカスタマイズ**
   - チーム固有のメトリクスを追加
   - ビジネスメトリクスも可視化

4. **さらに学ぶ**
   - SLI/SLOの設定
   - 分散トレーシングの深掘り
   - ログの構造化とベストプラクティス

---

## 🎉 おめでとうございます！

オブザーバビリティの三本柱を実際に体験しました。

**今日学んだことを振り返りましょう:**
- ✅ メトリクスで異常を検知
- ✅ トレースでボトルネックを特定
- ✅ ログで根本原因を解明
- ✅ 三本柱を連携させた調査

**この知識を持って、あなたは:**
- 勘や経験ではなく、データに基づいて判断できる
- 障害の平均修復時間（MTTR）を大幅に短縮できる
- システムの「なぜ」を理解できる

**オブザーバビリティは旅であり、目的地ではありません。**

継続的に改善し、データドリブンな文化を育てていきましょう！

---

## 📖 参考資料

- [GRAFANA_HOWTO.md](GRAFANA_HOWTO.md) - **Grafanaの使い方（初心者向け）**
- [LOKI_QUERY_FIXES.md](LOKI_QUERY_FIXES.md) - **Lokiクエリのよくある間違いと修正方法**
- [TRACE_ID_SEARCH_GUIDE.md](TRACE_ID_SEARCH_GUIDE.md) - **トレースIDでログを検索する詳細ガイド**
- [README.md](README.md) - プロジェクト全体の説明
- [LOAD_TESTING.md](LOAD_TESTING.md) - 負荷テストの詳細
- [GRAFANA_SETUP.md](GRAFANA_SETUP.md) - Grafana設定ガイド
- [API_ENDPOINTS.md](API_ENDPOINTS.md) - API仕様

## 💬 フィードバック

このガイドを改善するためのフィードバックをお待ちしています！

